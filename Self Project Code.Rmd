```{r}
paste("Title: Will the Telcom Customer Churn?- A Classification Analysis")
paste("Authors: Rajdeep Saha & Soumik Karmakar")
```

```{r}
rm(list=ls())
set.seed(1)
library(ggplot2)
library(leaps)
library(caret)
library(car)
library(corrplot)
library(tree)
library(MASS)
library(randomForest)
library(pROC)
```

```{r}
#data access
df <- read.csv('C:/Users/user/OneDrive/Desktop/abcd/WA_Fn-UseC_-Telco-Customer-Churn.csv')
head(df)
dim(df)
str(df)
n <- nrow(df)
```

```{r}
#id column remove
colnames(df)
df <- df[-which(colnames(df) == 'customerID')]
head(df)
```

```{r}
#missing value imputation
df$TotalCharges <- as.numeric(df$TotalCharges)
miss = which(is.na(df$TotalCharges) == TRUE)
df$TotalCharges[miss] <- median(df$TotalCharges, na.rm = TRUE) 
str(df)
```

```{r}
#No Service to No
for(i in (which(colnames(df) == 'OnlineSecurity') : which(colnames(df) == 'StreamingMovies'))){
  df[i] <- as.factor(ifelse(df[i] != 'Yes', 'No', 'Yes'))
}
df$InternetService <- as.factor(ifelse(df$InternetService != 'No', 'Yes', 'No'))
df$MultipleLines <- as.factor(ifelse(df$MultipleLines != 'Yes', 'No', 'Yes'))
df$SeniorCitizen <- as.factor(df$SeniorCitizen)

for(i in 1:ncol(df)){
  if(class(df[,i]) == 'character'){
    df[,i] <- as.factor(df[,i])
  }
}
str(df)
```

```{r}
#Correlation between numeric variables
cr <-cor(df[,c(5,18,19)])
corrplot(cr, method="circle")
```

```{r}
#EDA
p1 <- ggplot(df, aes(x = Churn, fill = Churn)) +facet_grid(~gender)+ geom_bar() +ggtitle("Churn - Gender") + theme_bw()
p2 <- ggplot(df, aes(x = Churn, fill = Churn)) +facet_grid(~SeniorCitizen)+ geom_bar() + ggtitle("Churn - SeniorCitizen") + theme_bw()
p3 <- ggplot(df, aes(x = Churn, fill = Churn)) +facet_grid(~Dependents)+ geom_bar() + ggtitle("Churn - Dependents") + theme_bw()
p4 <- ggplot(df, aes(x = Churn, fill = Churn)) +facet_grid(~Partner)+ geom_bar() + ggtitle("Churn - Partner") + theme_bw()
p5 <- ggplot(df, aes(x = Churn, fill = Churn)) +facet_grid(~PhoneService)+ geom_bar() + ggtitle("Churn - PhoneService")+ theme_bw()
p6 <- ggplot(df, aes(x = Churn, fill = Churn)) +facet_grid(~InternetService)+ geom_bar() + ggtitle("Churn - InternetService") + theme_bw()
p7 <- ggplot(df, aes(x = Churn, fill = Churn)) +facet_grid(~PaperlessBilling)+ geom_bar() + ggtitle("Churn - PaperlessBilling") + theme_bw()
p8 <- ggplot(df, aes(x = Churn, fill = Churn)) +facet_grid(~PaymentMethod)+ geom_bar() + ggtitle("Churn - Payment Method") + theme_bw()
ggpubr::ggarrange(p1,p2,p3,p4,p5,p6,p7,p8, nrow = 3, ncol = 3) 
```

```{r}
#dummification
attach(df)
to_dummy <- data.frame(Contract,PaymentMethod)
dmy <- dummyVars(" ~ .", data = to_dummy)
df2 <- data.frame(predict(dmy, newdata = to_dummy))
df2 <- df2[, !(colnames(df2) %in% c("Contract.Month.to.month", "PaymentMethod.Bank.transfer..automatic."))]
df <- df[,!(colnames(df) %in% c("Contract","PaymentMethod","TotalCharges"))]
df <- cbind(df, df2)
head(df)
attach(df)
dim(df)
```

```{r}
#Feature Selection

regfit.full=regsubsets(Churn~.,data=df,nvmax=21)
reg.summary=summary(regfit.full)
names(reg.summary)
which.max(reg.summary$adjr2)
plot(reg.summary$adjr2,xlab="No. of Variables",ylab=expression(paste("Adjusted","   ", "r"^"2")),type="l")
points(17,reg.summary$adjr2[17],col="red",cex=2,pch=20)
names(coef(regfit.full,17))[-1]
```

```{r}
#Final Dataset
data=df[,-c(1,2,8,20)]
dim(data)
```

```{r}
#train-test split:

index1=sample(1:nrow(data),floor(0.7*nrow(data)))
train=data[index1,]
remaining=data[-index1,]
index2=sample(1:nrow(remaining),floor(2/3*nrow(remaining)))
crossval=remaining[index2,]
test=remaining[-index2,]
actual_churn=crossval$Churn
```

```{r}
#logistic regression
logistic.fit=glm(Churn~.,data=train,family="binomial")
logistic.predict=rep("No",nrow(crossval))
predicted_prob=predict(logistic.fit,newdata=crossval,type="response")
logistic.predict[predicted_prob>0.5]="Yes"
table(logistic.predict,actual_churn)
mean(logistic.predict==actual_churn)
```

```{r}
#lda fit
lda.fit=lda(Churn~.,data=train)
lda.predict=predict(lda.fit,crossval)$class
table(lda.predict,actual_churn)
mean(lda.predict==actual_churn)
```

```{r}
#Classification Tree

tree.fit=tree(Churn~.,train,method="class")
summary(tree.fit)
plot(tree.fit)
text(tree.fit,pretty=0,cex=1)
tree.predict=predict(tree.fit,crossval,type="class")
table(predicted_churn=tree.predict,actual_churn)
mean(tree.predict==actual_churn)
```

```{r}
#Random Forest

rf.fit=randomForest(Churn~.,data=train,ntree=200,mtry=4)
rf.predict=predict(rf.fit,crossval)
table(predicted_churn=rf.predict,actual_churn)
mean(rf.predict==actual_churn)
```
```{r}
misclassification_rate_logistic=(mean(logistic.predict!=actual_churn))*100
misclassification_rate_lda=(mean(lda.predict!=actual_churn))*100
misclassification_rate_tree=(mean(tree.predict!=actual_churn))*100
misclassification_rate_forest=(mean(rf.predict!=actual_churn))*100
paste("Misclassification Error Rate for Logistic Regression is",misclassification_rate_logistic,"%")
paste("Misclassification Error Rate for Linear Discriminant Analysis is is",misclassification_rate_lda,"%")
paste("Misclassification Error Rate for Decision Tree is",misclassification_rate_tree,"%")
paste("Misclassification Error Rate for Random Forest is",misclassification_rate_forest,"%")
```

```{r}
#Choice is Logistic Regression
#Fit on full dataset
predicted_prob=predict(logistic.fit,newdata=test,type="response")
logistic.predict.test=rep("No",nrow(test))
logistic.predict.test[predicted_prob>0.5]="Yes"
actual.churn.test=test$Churn
table(logistic.predict.test,actual.churn.test)
misclassification.final=mean(logistic.predict.test!=actual.churn.test)*100
paste("Misclassification Error Rate for final model is",misclassification.final,"%")
```

```{r}
#Assessing final model accuracy via ROC curve
ROC=roc(actual.churn.test,predicted_prob)
plot(ROC,col="blue")
auc(ROC)
```

